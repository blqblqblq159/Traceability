{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b8ebfc",
   "metadata": {},
   "source": [
    "# Neo4j as a Traceability Solution\n",
    "In this notebook I will demonstrate why graph database Neo4j is a great candidate for the storage of manufacturing data when we want to trace all the processes from procurement of raw materials to production, consumption and disposal via a practical example.\n",
    "\n",
    "Some basic knowledge of neo4j, python and mySQL is assumed here, but it is possible to follow along without this knowledge.\n",
    "## Preparation of the example database\n",
    "In the practical example we take a look at data for an imaginary bread distribution process. Farmers produce grain, that is processed to flour by processors, further baked to bread by bakers and then distributed to bread machines where customers can make purchases.\n",
    "\n",
    "A Neo4j and mySQL instance in a docker container will be populated with this data by running the docker-compose.yml\n",
    "\n",
    "When this is done (some 60 seconds after docker-compose up), we can connect to the databases via python. Make sure py2neo, sqlalchemy and pandas are installed in the conda environment.\n",
    "\n",
    "We run a testQuery on both databases to make sure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14826c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   numberOfPurchases\n",
      "0              10000\n",
      "\n",
      "   numberOfPurchases\n",
      "0              10000\n"
     ]
    }
   ],
   "source": [
    "import py2neo\n",
    "import sqlalchemy as sql\n",
    "import pandas as pd\n",
    "\n",
    "graph = py2neo.Graph(\n",
    "    host=\"localhost\",\n",
    "    port=7687,\n",
    "    user=\"neo4j\",\n",
    "    password=\"connect\",\n",
    "    name=\"neo4j\"\n",
    ")\n",
    "\n",
    "df1 = pd.DataFrame(graph.run(\"MATCH (a:Purchase) RETURN count(a) as numberOfPurchases\").data())\n",
    "print(df1)\n",
    "\n",
    "db_connection_str = 'mysql+pymysql://root:debezium@localhost:3306/traceability'\n",
    "db_connection = sql.create_engine(db_connection_str)\n",
    "\n",
    "df2 = pd.read_sql('SELECT count(*) as numberOfPurchases FROM Buy', con=db_connection)\n",
    "print(\"\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa501a7",
   "metadata": {},
   "source": [
    "The previous queries should both yield 10000, as the datagenerator in docker-compose explicitly generates 10000 purchases. Now that we know everything is up and running we can compare some queries to showcase the power and flexibility of neo4j in the context of deeply nested data.\n",
    "## first Query scenario\n",
    "Let's imagine the scenario where there is Nuclear waste buried in the ground some place. The place was deserted and a farmer saw his opportunity to grow grains in the empty soil there. Grainbatch 0 was harvested there and processed all the way to bread that got distributed and sold. We now want to find all of the customers that bought bread originating from Grainbatch 0 to prevent them from eating the contaminated bread.\n",
    "\n",
    "In Neo4j, we do this via the following Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3960264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct affected customers:\n",
      "1950\n",
      "\n",
      "Ids of 5 affected customers:\n",
      "   CustomerID\n",
      "0         971\n",
      "1        2394\n",
      "2         249\n",
      "3        2478\n",
      "4        2177\n"
     ]
    }
   ],
   "source": [
    "Query = \"MATCH (:Grainbatch {id:0})-[*]->(a:Customer) RETURN DISTINCT a.id as CustomerID\"\n",
    "\n",
    "df = pd.DataFrame(graph.run(Query).data())\n",
    "\n",
    "print(\"Number of distinct affected customers:\")\n",
    "print(df[\"CustomerID\"].count())\n",
    "print(\"\")\n",
    "print(\"Ids of 5 affected customers:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc031c73",
   "metadata": {},
   "source": [
    "We used the \"-\\[*\\]->\" statement in the query to signify that we want to look any path length downstream from Grainbatch 0, find the customers there and then return all of the distinct customer ids that we found. Very simple\n",
    "\n",
    "Now let's build the same Query for the mySQL table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9d224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct affected customers:\n",
      "1950\n",
      "\n",
      "Ids of 5 affected customers:\n",
      "   CustomerID\n",
      "0        2594\n",
      "1        2580\n",
      "2        4498\n",
      "3        3104\n",
      "4        4183\n"
     ]
    }
   ],
   "source": [
    "Query = \"\"\"SELECT DISTINCT CustomerID\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Process as p\n",
    "        ON b.ProcessBatchnr = p.Batchnr\n",
    "        WHERE p.FarmBatchnr = 0\"\"\"\n",
    "\n",
    "df = pd.read_sql(Query, con=db_connection)\n",
    "\n",
    "print(\"Number of distinct affected customers:\")\n",
    "print(len(df))\n",
    "print(\"\")\n",
    "print(\"Ids of 5 affected customers:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1285a",
   "metadata": {},
   "source": [
    "This Query was clearly a lot more involved. We required 3 JOIN statements and to implement these JOINs, we have to explicitly know which tables to relate to one another (Buy relates to Dist relates to Bake relates to Process) and which columns relate the tables to eachother; A lot more overhead than is required in the neo4j query.\n",
    "\n",
    "## second Query scenario\n",
    "\n",
    "Imagine now a scenario where for some bread types we don't just use flour from Flourbatches, but we first refine the Flour in another process as is shown in the Figure FIGUUR MAKEN.\n",
    "\n",
    "In mySQL we would have to explicitly know all the different ways the grainbatch gets processed and consumed downstream by customers and implement all the different ways our tables have to be JOINed. This is very prone to error.\n",
    "\n",
    "In Neo4j, we would have to change nothing about our previous Query. We can completely rely on the flexibility of the \"-\\[*\\]->\" query statement.\n",
    "\n",
    "## third Query scenario\n",
    "\n",
    "Customers can give ratings to their bread purchases. Imagine some purchase recieves a very bad rating. We want to Query our database to see where the bad rating comes from. Assuming the bread was rated badly for good reason, we can attempt to look upstream in our production process to check where the problem could lie.\n",
    "\n",
    "If the problem lies within the distribution process, we can imagine that a lot of the purchases downstream from this distribution process have a bad rating. If the problem lies with the baking process, we can imagine that that a lot of the purchases downstream from this baking process have a bad rating (this necessarily implies that a lot of the purchases downstream from the distribution process have a bad rating as well, since the distribution process lies downstream from the bad bakin process).\n",
    "A similar reasoning goes for the flour processing process and the grain harvesting process.\n",
    "\n",
    "So what we want to do is query upstream from the bad purchase to find its parent distribution, baking, flour processing and harvesting process and from these processes check back downstream for all their respective child purchases and check the ratio of bad ratings on these purchases.\n",
    "\n",
    "First an auxiliary query is necessary to find a suitable badly rated purchase for this example (Using neo4j for this :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3eba2950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suitable badly rated Purchase found with ID:\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "#find a flourbatch with a lot of badly rated child purchases\n",
    "Query = \"\"\"MATCH (a:Flourbatch)-[*]->(b:Purchase) \n",
    "        WITH a, collect(b) as allPurchases \n",
    "        WITH size([x in allPurchases where x.goodrating = false]) as top,\n",
    "            size(allPurchases)*1.0 as bottom, allPurchases\n",
    "        WHERE top/bottom > 0.8 RETURN allPurchases[0].id as CustomerID\"\"\"\n",
    "\n",
    "badPurchaseID = graph.run(Query).data()[0][\"CustomerID\"]\n",
    "print(\"Suitable badly rated Purchase found with ID:\")\n",
    "print(badPurchaseID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa47d00",
   "metadata": {},
   "source": [
    "Now we utilise neo4j to Query for the above scenario using the badly rated purchase that we found in the auxiliary Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8a86ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      batchType  batchID badratingPercentage\n",
      "0    Grainbatch        0                 35%\n",
      "1    Flourbatch        4                 91%\n",
      "2    Breadbatch       24                 88%\n",
      "3  Machinebatch      121                 90%\n"
     ]
    }
   ],
   "source": [
    "Query = f\"\"\"UNWIND ['Grainbatch','Flourbatch','Breadbatch','Machinebatch'] AS y\n",
    "        match (:Purchase {{id:{badPurchaseID}}})<-[*]-(a) where labels(a)=[y] WITH a,y\n",
    "        MATCH (a)-[*]->(b:Purchase) WITH a.id AS batchID, collect(b) AS allPurchases, y\n",
    "        WITH batchID, y,\n",
    "            size([x in allPurchases where x.goodrating = false]) as top,\n",
    "            size(allPurchases)*1.0 as bottom\n",
    "        RETURN y as batchType, batchID, top/bottom as badratingPercentage\"\"\"\n",
    "\n",
    "df = pd.DataFrame(graph.run(Query).data())\n",
    "df[\"badratingPercentage\"] = df[\"badratingPercentage\"].map(\"{:.0%}\".format)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab1978",
   "metadata": {},
   "source": [
    "We find that the flourbatch, breadbatch and machinebatch all have a lot of badly rated purchases as children. Since the flourbatch is the highest in the parent-child relation, we find that the problem lies with the flourbatch and we should contact the flour processing firm that made the flourbatch.\n",
    "\n",
    "The Neo4j query above is a bit more involved than just the \"-\\[\\*\\]->\" that we used previously, but for what the query ended up doing it's still very compact and again very flexible through the use of the \"-\\[\\*\\]->\" statement.\n",
    "\n",
    "Now let's try to build this same query in mySQL (wish me luck):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "843dff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      batchType batchID badratingPercentage\n",
      "0    Grainbatch       0                 35%\n",
      "1    Flourbatch       4                 91%\n",
      "2    Breadbatch      24                 88%\n",
      "3  Machinebatch     121                 90%\n"
     ]
    }
   ],
   "source": [
    "column_names = ['batchType','batchID','badratingPercentage']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, f.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Process as p\n",
    "        ON b.ProcessBatchnr = p.Batchnr\n",
    "        INNER JOIN Farm as f\n",
    "        ON p.FarmBatchnr = f.Batchnr\n",
    "        INNER JOIN Process as p2\n",
    "        ON p2.FarmBatchnr = f.Batchnr\n",
    "        INNER JOIN Bake as b2\n",
    "        ON b2.ProcessBatchnr = p2.Batchnr\n",
    "        INNER JOIN Dist as d2\n",
    "        ON d2.BakeBatchnr = b2.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d2.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "farm_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Grainbatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':farm_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, p.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Process as p\n",
    "        ON b.ProcessBatchnr = p.Batchnr\n",
    "        INNER JOIN Bake as b2\n",
    "        ON b2.ProcessBatchnr = p.Batchnr\n",
    "        INNER JOIN Dist as d2\n",
    "        ON d2.BakeBatchnr = b2.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d2.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "flour_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Flourbatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':flour_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, b.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Dist as d2\n",
    "        ON d2.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d2.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "bake_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Breadbatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':bake_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, d.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "dist_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Machinebatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':dist_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd26e4",
   "metadata": {},
   "source": [
    "In contrast to the neo4j Query where we iterate over a list to do everything at once, I could not manage to do everything in a single mySQL query, and had to write an individual query for every upstream process. The mySQL queries are also far from elegant.\n",
    "\n",
    "Here again, neo4j's flexibility shines through: Suppose we have an additional process upstream from the badly rated purchase that we are following (like for example the flour refinery that we mentioned earlier). All we have to do to include this process in the neo4j Query is add it to the inital UNWIND list (see neo4j query code block). Doing this in mySQL would require us to make yet another error-prone query with a ton of joins.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We've made a comparison of neo4j and mySQL as database solutions for a fictitious traceability problem. We find that neo4j allows us to elegantly query this kind of deeply nested data, while other database solutions are significantly less flexible and more error-prone in this context.\n",
    "\n",
    "In this notebook we showed just a couple of simple queries, but there is a whole host of graph data science tools for neo4j as well for the more data scientifically inclined reader: https://neo4j.com/product/graph-data-science-library/\n",
    "\n",
    "I hope you enjoyed this short notebook showcasing some of the advantages of neo4j. If you have any questions, remarks or suggestions, I'd be delighted to hear from you at: wannes.debreuck@humain.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
