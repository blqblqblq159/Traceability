{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b8ebfc",
   "metadata": {},
   "source": [
    "# Neo4j as a Traceability Solution\n",
    "In this notebook I will demonstrate why graph database Neo4j is a great candidate for the storage of manufacturing data when we want to trace all the processes from procurement of raw materials to production, consumption and disposal via a practical example.\n",
    "\n",
    "Some basic knowledge of neo4j, python and mySQL could come in handy, but it is defnitely possible to follow along without this knowledge.\n",
    "## Preparation of the example database\n",
    "In the practical example we take a look at data for an imaginary bread distribution process. Farmers produce grain, that is processed to flour by processors, further baked to bread by bakers and then distributed to bread machines where customers can make purchases. The schema of our data looks as follows, where the important part for the query examples below is encircled:\n",
    "\n",
    "![alt text](figure1.png \"Title\")\n",
    "\n",
    "A Neo4j and mySQL instance in a docker container will be populated with this data by running the docker-compose.yml\n",
    "\n",
    "When this is done (some 60 seconds after docker-compose up), we can connect to the databases via python. Make sure py2neo, sqlalchemy and pandas are installed in the conda environment.\n",
    "\n",
    "We run a testquery on both databases to connect to our databases and make sure everything is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14826c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j output:\n",
      "   numberOfPurchases\n",
      "0              10000\n",
      "\n",
      "mySQL output:\n",
      "   numberOfPurchases\n",
      "0              10000\n"
     ]
    }
   ],
   "source": [
    "import py2neo\n",
    "import sqlalchemy as sql\n",
    "import pandas as pd\n",
    "\n",
    "graph = py2neo.Graph(\n",
    "    host=\"localhost\",\n",
    "    port=7687,\n",
    "    user=\"neo4j\",\n",
    "    password=\"connect\",\n",
    "    name=\"neo4j\"\n",
    ")\n",
    "\n",
    "df1 = pd.DataFrame(graph.run(\"MATCH (a:Purchase) RETURN count(a) as numberOfPurchases\").data())\n",
    "print(\"Neo4j output:\")\n",
    "print(df1)\n",
    "\n",
    "db_connection_str = 'mysql+pymysql://root:debezium@localhost:3306/traceability'\n",
    "db_connection = sql.create_engine(db_connection_str)\n",
    "\n",
    "df2 = pd.read_sql('SELECT count(*) as numberOfPurchases FROM Buy', con=db_connection)\n",
    "print(\"\")\n",
    "print(\"mySQL output:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa501a7",
   "metadata": {},
   "source": [
    "The previous queries should both yield 10000, as the datagenerator in docker-compose explicitly generates 10000 purchases. Now that we know everything is up and running we can compare some queries to showcase the power and flexibility of neo4j in the context of deeply nested data.\n",
    "## first Query scenario\n",
    "Let's imagine the scenario where a hardworking farmer harvests a batch of grain, let's say Grainbatch 0. Unbenownst to him, some chemical company in the area has been dumping their waste products in the vicinity, contaminating the soil and the Grainbatch that he harvested. As such, all the bread that is produced from this Grainbatch is contaminated and we want to find all the customers that bought bread originating from Grainbatch 0 to alert them and hopefully prevent them from consuming it.\n",
    "\n",
    "In Neo4j, we do this via the following Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3960264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct affected customers:\n",
      "1981\n",
      "\n",
      "Ids of 5 affected customers:\n",
      "   CustomerID\n",
      "0        3261\n",
      "1        1017\n",
      "2        4357\n",
      "3        4423\n",
      "4        4930\n"
     ]
    }
   ],
   "source": [
    "Query = \"MATCH (:Grainbatch {id:0})-[*]->(a:Customer) RETURN DISTINCT a.id as CustomerID\"\n",
    "\n",
    "df = pd.DataFrame(graph.run(Query).data())\n",
    "\n",
    "print(\"Number of distinct affected customers:\")\n",
    "print(df[\"CustomerID\"].count())\n",
    "print(\"\")\n",
    "print(\"Ids of 5 affected customers:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc031c73",
   "metadata": {},
   "source": [
    "We used the \"-\\[*\\]->\" statement in the query to signify that we want to look any path length downstream from Grainbatch 0, find the customers there and then return all of the distinct customer ids that we found. Very simple\n",
    "\n",
    "Now let's build the same query for mySQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d9d224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct affected customers:\n",
      "1981\n",
      "\n",
      "Ids of 5 affected customers:\n",
      "   CustomerID\n",
      "0        1963\n",
      "1        4348\n",
      "2        4314\n",
      "3        3142\n",
      "4        4301\n"
     ]
    }
   ],
   "source": [
    "Query = \"\"\"SELECT DISTINCT CustomerID\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Process as p\n",
    "        ON b.ProcessBatchnr = p.Batchnr\n",
    "        WHERE p.FarmBatchnr = 0\"\"\"\n",
    "\n",
    "df = pd.read_sql(Query, con=db_connection)\n",
    "\n",
    "print(\"Number of distinct affected customers:\")\n",
    "print(len(df))\n",
    "print(\"\")\n",
    "print(\"Ids of 5 affected customers:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1285a",
   "metadata": {},
   "source": [
    "This query was clearly a lot more involved. We required 3 JOIN statements. And in order to implement these JOINs, we have to explicitly know which tables to relate to one another ('Buy' relates to 'Dist' relates to 'Bake' relates to 'Process') and which columns relate the tables to eachother. The neo4j query required significantly less overhead.\n",
    "\n",
    "## second Query scenario\n",
    "\n",
    "Imagine now a scenario where for some bread types we don't just use flour from Flourbatches, but we first refine the Flour in another process as is shown in following figure:\n",
    "\n",
    "![alt text](figure2.png \"Title\")\n",
    "\n",
    "In mySQL we would have to explicitly know all the different ways the Grainbatch gets processed and consumed downstream by customers and implement all the different ways our tables have to be JOINed. This is very prone to error.\n",
    "\n",
    "In Neo4j, we would have to change nothing about our previous Query. We can completely rely on the flexibility of the \"-\\[*\\]->\" query statement.\n",
    "\n",
    "## third Query scenario\n",
    "\n",
    "Customers can give ratings to their bread purchases. Imagine some purchase recieves a very bad rating. We want to Query our database to see where the bad rating comes from. Assuming the bread was rated badly for good reason, we can attempt to look upstream in our production process to check where the problem could lie.\n",
    "\n",
    "If the problem lies within the distribution process, we can imagine that a lot of the purchases downstream from this distribution process have a bad rating. If the problem lies with the baking process, we can imagine that that a lot of the purchases downstream from this baking process have a bad rating (this necessarily implies that a lot of the purchases downstream from the distribution process have a bad rating as well, since the distribution process lies downstream from the bad baking process).\n",
    "A similar reasoning goes for the flour processing process and the grain harvesting process.\n",
    "\n",
    "So what we want to do is query upstream from the bad purchase to find its parent distribution, baking, flour processing and harvesting process and from these processes check back downstream for all their respective child purchases and check the ratio of bad ratings on these purchases. The query for this will follow the colored arrows from the figure below:\n",
    "\n",
    "![alt text](figure3.png \"Title\")\n",
    "\n",
    "First an auxiliary query is necessary to find a suitable badly rated purchase for this example (Using neo4j for this :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eba2950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suitable badly rated Purchase found with ID:\n",
      "294\n"
     ]
    }
   ],
   "source": [
    "#find a flourbatch with a lot of badly rated child purchases\n",
    "Query = \"\"\"MATCH (a:Flourbatch)-[*]->(b:Purchase)\n",
    "        WITH a, collect(b) as allPurchases \n",
    "        WITH size([x in allPurchases where x.goodrating = false]) as top,\n",
    "            size(allPurchases)*1.0 as bottom, allPurchases\n",
    "        WHERE top/bottom > 0.8 RETURN allPurchases[0].id as CustomerID\"\"\"\n",
    "\n",
    "badPurchaseID = graph.run(Query).data()[0][\"CustomerID\"]\n",
    "print(\"Suitable badly rated Purchase found with ID:\")\n",
    "print(badPurchaseID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa47d00",
   "metadata": {},
   "source": [
    "Now we utilise neo4j to query for the above scenario using the badly rated purchase that we found in the auxiliary query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8a86ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      batchType  batchID badratingPercentage\n",
      "0    Grainbatch        0                 34%\n",
      "1    Flourbatch        0                 89%\n",
      "2    Breadbatch        0                 91%\n",
      "3  Machinebatch        4                 90%\n"
     ]
    }
   ],
   "source": [
    "Query = f\"\"\"UNWIND ['Grainbatch','Flourbatch','Breadbatch','Machinebatch'] AS y\n",
    "        MATCH (:Purchase {{id:{badPurchaseID}}})<-[*]-(a) where labels(a)=[y] WITH a,y\n",
    "        MATCH (a)-[*]->(b:Purchase) WITH a.id AS batchID, collect(distinct b) AS allPurchases, y\n",
    "        WITH batchID, y,\n",
    "            size([x in allPurchases where x.goodrating = false]) as top,\n",
    "            size(allPurchases)*1.0 as bottom\n",
    "        RETURN y as batchType, batchID, top/bottom as badratingPercentage\"\"\"\n",
    "\n",
    "df = pd.DataFrame(graph.run(Query).data())\n",
    "df[\"badratingPercentage\"] = df[\"badratingPercentage\"].map(\"{:.0%}\".format)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab1978",
   "metadata": {},
   "source": [
    "We find that the flourbatch, breadbatch and machinebatch all have a lot of badly rated purchases as children. Since the flourbatch is the highest in the parent-child relation, we find that the problem lies with the flourbatch and we should contact the flour processing firm that made the flourbatch.\n",
    "\n",
    "The Neo4j query above is a bit more involved than just the \"-\\[\\*\\]->\" that we used previously, but for what the query ended up doing it's still very compact and again very flexible through the use of the \"-\\[\\*\\]->\" statement.\n",
    "\n",
    "Now let's try to build this same query in mySQL (wish me luck):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "843dff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      batchType batchID badratingPercentage\n",
      "0    Grainbatch       0                 34%\n",
      "1    Flourbatch       0                 89%\n",
      "2    Breadbatch       0                 91%\n",
      "3  Machinebatch       4                 90%\n"
     ]
    }
   ],
   "source": [
    "column_names = ['batchType','batchID','badratingPercentage']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, f.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Process as p\n",
    "        ON b.ProcessBatchnr = p.Batchnr\n",
    "        INNER JOIN Farm as f\n",
    "        ON p.FarmBatchnr = f.Batchnr\n",
    "        INNER JOIN Process as p2\n",
    "        ON p2.FarmBatchnr = f.Batchnr\n",
    "        INNER JOIN Bake as b2\n",
    "        ON b2.ProcessBatchnr = p2.Batchnr\n",
    "        INNER JOIN Dist as d2\n",
    "        ON d2.BakeBatchnr = b2.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d2.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "farm_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Grainbatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':farm_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, p.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Process as p\n",
    "        ON b.ProcessBatchnr = p.Batchnr\n",
    "        INNER JOIN Bake as b2\n",
    "        ON b2.ProcessBatchnr = p.Batchnr\n",
    "        INNER JOIN Dist as d2\n",
    "        ON d2.BakeBatchnr = b2.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d2.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "flour_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Flourbatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':flour_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, b.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Bake AS b\n",
    "        ON d.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Dist as d2\n",
    "        ON d2.BakeBatchnr = b.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d2.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "bake_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Breadbatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':bake_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "Query = f\"\"\"SELECT Buy.goodrating, d.Batchnr\n",
    "        FROM Buy\n",
    "        INNER JOIN Dist AS d\n",
    "        ON Buy.MachineBatchnr = d.Batchnr\n",
    "        INNER JOIN Buy as Buy2\n",
    "        ON Buy2.MachineBatchnr = d.Batchnr\n",
    "        WHERE Buy2.purchaseID = {badPurchaseID};\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(Query, con=db_connection)\n",
    "dist_badrating = \"{:.0%}\".format(1 - sum(df1[\"goodrating\"])/len(df1))\n",
    "row = {'batchType':'Machinebatch', 'batchID':df1['Batchnr'][0], 'badratingPercentage':dist_badrating}\n",
    "df = df.append(row, ignore_index = True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd26e4",
   "metadata": {},
   "source": [
    "In contrast to the neo4j Query where we iterate over a list to do everything at once, I could not manage to do everything in a single mySQL query, and had to write an individual query for every upstream process. The mySQL queries are also far from elegant.\n",
    "\n",
    "Here again, neo4j's flexibility shines through: Suppose we have an additional process upstream from the badly rated purchase that we are following (like for example the flour refinery that we mentioned earlier). All we have to do to include this process in the neo4j Query is add it to the inital UNWIND list (see neo4j query code block). Doing this in mySQL would require us to make yet another error-prone query with a ton of joins.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We've made a comparison of neo4j and mySQL as database solutions for a fictitious traceability problem. We find that neo4j allows us to elegantly query this kind of deeply nested data, while other database solutions are significantly less flexible and more error-prone in this context.\n",
    "\n",
    "In this notebook we showed just a couple of simple direct queries. For the more data scientifically inclined reader, there is a whole host of graph data science tools for neo4j as well: https://neo4j.com/product/graph-data-science-library/\n",
    "\n",
    "I hope you enjoyed this short notebook showcasing some of the advantages of neo4j. If you have any questions, remarks or suggestions, I'd be delighted to hear from you at: wannes.debreuck@humain.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
